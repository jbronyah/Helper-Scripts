{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncommment below line to install ruptures if not already installed\n",
    "\n",
    "# !python -m pip install ruptures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ruptures as rpt\n",
    "from scipy.stats import zscore, linregress, iqr, skew, kurtosis\n",
    "import numpy as np\n",
    "import xlsxwriter\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Please enter the below details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penalty = 1 # higher means less cells\n",
    "dim = 'Cell Name' # dimension you are interested in\n",
    "dim_net ='Whole Network'\n",
    "date = 'Date'     # date variable\n",
    "img_dir = \"C:/Users/BronyahJ/images/\" # path to store images\n",
    "source_file_path = \"C:\\\\Users\\\\BronyahJ\\\\Downloads\\\\\" # where your source data is located\n",
    "file_name = \"2G_SSV_Acceptance_v1_Query_Result_20230208161517190.xlsx\" # source filename\n",
    "Tech = '2G'\n",
    "cells_sheet = 0\n",
    "network_sheet = 1\n",
    "network_sheet_cells = 2\n",
    "scale_data = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify columns you want to delete in the to_delete list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REMOVE_NA = True\n",
    "to_delete = ['LocalCell Id','Integrity', 'Cell ID', 'Cell CI', 'CellIndex','NR Cell ID','Cell FDD TDD Indication']\n",
    "KNOWN_NA_VALS = ['NIL', 'NILL', 'NULL', 'NA', '#NA', '#N/A', 'N/A','#VALUE!','#REF!','#DIV/0!','#NUM!','#NAME?','#NULL!','NAN','nan','NaN','/0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_st = datetime.now()\n",
    "\n",
    "if str(file_name).split(\".\")[-1] == 'xlsx' or str(file_name).split(\".\")[-1] == 'xls':\n",
    "    df = pd.read_excel(source_file_path+file_name,sheet_name=cells_sheet)\n",
    "    df01 = pd.read_excel(source_file_path+file_name,sheet_name=network_sheet_cells)\n",
    "    \n",
    "    \n",
    "elif str(file_name).split(\".\")[-1] == 'csv':\n",
    "    df  = pd.read_csv(source_file_path+file_name,skiprows=6)\n",
    "\n",
    "imp_end= datetime.now()\n",
    "print(\"It took {} time to import data\".format(imp_end-imp_st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(to_delete) > 0:\n",
    "    df = df.drop([x for x in to_delete if x in df.columns], axis=1)\n",
    "    df01 = df01.drop([x for x in to_delete if x in df01.columns], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################\n",
    "# Experimental code here. Trying to replace Known values which means NULL / NA to np.nan\n",
    "# Ideally this should help our analysis.\n",
    "############################################################################################\n",
    "for x in [x for x in df.columns if df[x].dtype.kind.lower() in ('o', 's', 'u', 'v')]:\n",
    "    if len(df[df[x].isin(KNOWN_NA_VALS)]) > 0: #some instances were found with Known NA substitutions\n",
    "        df.loc[ df[x].isin(KNOWN_NA_VALS), x ] = np.nan\n",
    "        print(\"Found some known NA substitutions in {}. Will replace and try to force as numeric\".format(x))\n",
    "        try: #now we will try to see if the column can become numeric\n",
    "            df[x] = pd.to_numeric(df[x], errors='raise')\n",
    "        except ValueError as e:\n",
    "            continue #Column cannot be converted to numeric. Just continue\n",
    "############################################################################################\n",
    "\n",
    "############################################################################################\n",
    "# Experiment 2: If all endings are % or $ or # then we will try to strip these and check if \n",
    "#     the column can be converted as a numeric value\n",
    "############################################################################################\n",
    "sp_endings = ['%', '$', '#', '£', 'QAR', 'GBP', 'qar', 'gbp', 'usd', 'USD' ,'eur', 'EUR']\n",
    "\n",
    "for x in [x for x in df.columns if df[x].dtype.kind.lower() in ('o', 's', 'u', 'v')]:\n",
    "    for sp in sp_endings:\n",
    "        totals = df[x].astype(str).str.endswith(sp).sum() + df[x].isna().sum()\n",
    "        if totals == len(df): #Either all entries end with special char or are null\n",
    "            temp = df[x].astype(str).str.replace(sp, '')\n",
    "            try:\n",
    "                temp_numeric = pd.to_numeric(temp, errors='raise')\n",
    "                df[x] = temp_numeric #if we were able to convert to numeric then we keep this\n",
    "                                    # in our dataframe. else no change\n",
    "                print(\"Modified column {} for special endings {} and changed to numeric\".format(\n",
    "                        x, sp))\n",
    "            except ValueError as ve:\n",
    "                continue\n",
    "############################################################################################\n",
    "# Same code as above but for string beginnings\n",
    "\n",
    "for x in [x for x in df.columns if df[x].dtype.kind.lower() in ('o', 's', 'u', 'v')]:\n",
    "    for sp in sp_endings:\n",
    "        totals = df[x].astype(str).str.startswith(sp).sum() + df[x].isna().sum()\n",
    "        if totals == len(df): #Either all entries end with special char or are null\n",
    "            temp = df[x].astype(str).str.replace(sp, '')\n",
    "            try:\n",
    "                temp_numeric = pd.to_numeric(temp, errors='raise')\n",
    "                df[x] = temp_numeric #if we were able to convert to numeric then we keep this\n",
    "                                    # in our dataframe. else no change\n",
    "                print(\"Modified column {} for special startings {} and changed to numeric\".format(\n",
    "                        x, sp))\n",
    "            except ValueError as ve:\n",
    "                continue\n",
    "############################################################################################\n",
    "# Now we have to deal with NA values\n",
    "if REMOVE_NA == True:\n",
    "    df = df.dropna(axis=0, how='all')\n",
    "else:\n",
    "    for x in [x for x in df.columns]:\n",
    "        if df[x].dtype.kind in ('f', 'c', 'i', 'u'):\n",
    "            df[x].fillna(df[x].median(),inplace=True)\n",
    "    df = df.fillna(method='ffill')\n",
    "    df = df.fillna(method='bfill')\n",
    "############################################################################################\n",
    "\n",
    "    \n",
    "############################################################################################    \n",
    "# WARNING - DONT REMOVE BELOW WITHOUT UNDERSTANDING OF THE CODE BIT\n",
    "# This step is mandatory. We will delete any column if it is Completely np.nan\n",
    "a = df.isna().sum(axis=0)\n",
    "FULL_NA_COLS = [x for x in a[df.isna().sum(axis=0) == len(df)].index]\n",
    "df = df.drop(FULL_NA_COLS, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################\n",
    "# Experimental code here. Trying to replace Known values which means NULL / NA to np.nan\n",
    "# Ideally this should help our analysis.\n",
    "############################################################################################\n",
    "for x in [x for x in df01.columns if df01[x].dtype.kind.lower() in ('o', 's', 'u', 'v')]:\n",
    "    if len(df01[df01[x].isin(KNOWN_NA_VALS)]) > 0: #some instances were found with Known NA substitutions\n",
    "        df01.loc[ df01[x].isin(KNOWN_NA_VALS), x ] = np.nan\n",
    "        print(\"Found some known NA substitutions in {}. Will replace and try to force as numeric\".format(x))\n",
    "        try: #now we will try to see if the column can become numeric\n",
    "            df01[x] = pd.to_numeric(df01[x], errors='raise')\n",
    "        except ValueError as e:\n",
    "            continue #Column cannot be converted to numeric. Just continue\n",
    "############################################################################################\n",
    "\n",
    "############################################################################################\n",
    "# Experiment 2: If all endings are % or $ or # then we will try to strip these and check if \n",
    "#     the column can be converted as a numeric value\n",
    "############################################################################################\n",
    "sp_endings = ['%', '$', '#', '£', 'QAR', 'GBP', 'qar', 'gbp', 'usd', 'USD' ,'eur', 'EUR']\n",
    "\n",
    "for x in [x for x in df01.columns if df01[x].dtype.kind.lower() in ('o', 's', 'u', 'v')]:\n",
    "    for sp in sp_endings:\n",
    "        totals = df01[x].astype(str).str.endswith(sp).sum() + df01[x].isna().sum()\n",
    "        if totals == len(df01): #Either all entries end with special char or are null\n",
    "            temp = df01[x].astype(str).str.replace(sp, '')\n",
    "            try:\n",
    "                temp_numeric = pd.to_numeric(temp, errors='raise')\n",
    "                df01[x] = temp_numeric #if we were able to convert to numeric then we keep this\n",
    "                                    # in our dataframe. else no change\n",
    "                print(\"Modified column {} for special endings {} and changed to numeric\".format(\n",
    "                        x, sp))\n",
    "            except ValueError as ve:\n",
    "                continue\n",
    "############################################################################################\n",
    "# Same code as above but for string beginnings\n",
    "\n",
    "for x in [x for x in df01.columns if df01[x].dtype.kind.lower() in ('o', 's', 'u', 'v')]:\n",
    "    for sp in sp_endings:\n",
    "        totals = df01[x].astype(str).str.startswith(sp).sum() + df01[x].isna().sum()\n",
    "        if totals == len(df01): #Either all entries end with special char or are null\n",
    "            temp = df01[x].astype(str).str.replace(sp, '')\n",
    "            try:\n",
    "                temp_numeric = pd.to_numeric(temp, errors='raise')\n",
    "                df01[x] = temp_numeric #if we were able to convert to numeric then we keep this\n",
    "                                    # in our dataframe. else no change\n",
    "                print(\"Modified column {} for special startings {} and changed to numeric\".format(\n",
    "                        x, sp))\n",
    "            except ValueError as ve:\n",
    "                continue\n",
    "############################################################################################\n",
    "# Now we have to deal with NA values\n",
    "if REMOVE_NA == True:\n",
    "    df01 = df01.dropna(axis=0, how='all')\n",
    "else:\n",
    "    for x in [x for x in df01.columns]:\n",
    "        if df01[x].dtype.kind in ('f', 'c', 'i', 'u'):\n",
    "            df01[x].fillna(df01[x].median(),inplace=True)\n",
    "    df01 = df01.fillna(method='ffill')\n",
    "    df01 = df01.fillna(method='bfill')\n",
    "############################################################################################\n",
    "\n",
    "    \n",
    "############################################################################################    \n",
    "# WARNING - DONT REMOVE BELOW WITHOUT UNDERSTANDING OF THE CODE BIT\n",
    "# This step is mandatory. We will delete any column if it is Completely np.nan\n",
    "a = df01.isna().sum(axis=0)\n",
    "FULL_NA_COLS = [x for x in a[df01.isna().sum(axis=0) == len(df01)].index]\n",
    "df01 = df01.drop(FULL_NA_COLS, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True,drop=True)\n",
    "df01.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df01.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df01.pivot_table(index=date, aggfunc=np.nanmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1 = df01.pivot_table(index=date, aggfunc=np.nanstd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df01 = df01.dropna(axis=0, how='any')\n",
    "df01.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df01.isnull().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df01.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df02=df01.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpi_net = []\n",
    "kpi_net_2 = []\n",
    "kpi_net_3 = []\n",
    "kpi_net_4 = []\n",
    "kpi_net_5 = []\n",
    "\n",
    "for x in [x for x in df02.columns if df02[x].dtype.kind.lower() not in ('o', 's', 'u', 'v','m')]:\n",
    "    \n",
    "    \n",
    "    if scale_data:\n",
    "        for k in  np.arange(0,len(df02[x])):\n",
    "            df02[x].iloc[k] -= df02[x].min()\n",
    "            if (df02[x].max()-df02[x].min()) > 0:\n",
    "                df02[x].iloc[k] /= (df02[x].max()-df02[x].min())\n",
    "            else:\n",
    "                df02[x].iloc[k] = 0\n",
    "                \n",
    "            \n",
    "                  \n",
    "        \n",
    "\n",
    "                \n",
    "            \n",
    "    high_count = 0\n",
    "    low_count = 0\n",
    "    IQR = iqr(df02[x].values, nan_policy='omit')\n",
    "    Q1 = np.nanpercentile(df02[x].values,25)\n",
    "    Q3 = np.nanpercentile(df02[x].values,75)\n",
    "    low_limit = Q1 - 1.5*IQR\n",
    "    high_limit = Q3 + 1.5*IQR\n",
    "    sk = skew(df02[x].values, nan_policy='omit')\n",
    "    kurt = kurtosis(df02[x].values, nan_policy='omit')\n",
    "    \n",
    "    #high_limit = np.nanmean(df02[x].values) - (3*np.nanstd(df02[x].values))\n",
    "    #low_limit = np.nanmean(df02[x].values) + (3*np.nanstd(df02[x].values))\n",
    "    \n",
    "    if Q3 == Q1:\n",
    "        \n",
    "        for i in np.arange(0,df02[x].shape[0]):\n",
    "            if df02[x][i] > high_limit:\n",
    "                high_count = high_count + 1\n",
    "                \n",
    "            elif df02[x][i] < low_limit:\n",
    "                low_count = low_count + 1\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        for i in np.arange(0,df02[x].shape[0]):\n",
    "            if (df02[x][i] >= high_limit) and (low_limit != high_limit) :\n",
    "                high_count = high_count + 1\n",
    "                \n",
    "            elif (df02[x][i] <= low_limit) and (low_limit != high_limit):\n",
    "                low_count = low_count + 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    kpi_net_3.append(x)\n",
    "    kpi_net.append(high_count)\n",
    "    kpi_net_2.append(low_count)\n",
    "    kpi_net_4.append(sk)\n",
    "    kpi_net_5.append(kurt)\n",
    "    \n",
    "            \n",
    "        \n",
    "kpis_df = pd.DataFrame([kpi_net_3,kpi_net,kpi_net_2,kpi_net_4,kpi_net_5], index=['kpi', 'high','low','skew','kurt']).T  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_ssv = []\n",
    "kpi =[]\n",
    "value = []\n",
    "status = []\n",
    "network_avg = []\n",
    "\n",
    "\n",
    "for x in [x for x in df.columns if df[x].dtype.kind.lower() not in ('o', 's', 'u', 'v','m')]:\n",
    "    \n",
    "    df_cell = df.pivot_table(index=dim, columns=date, values=x, aggfunc=np.mean)\n",
    "    \n",
    "    for i in np.arange(0,df_cell.shape[0]):\n",
    "        \n",
    "        high=df_test[x][0] + (3 * df_test1[x][0])\n",
    "        low= df_test[x][0] - (3 * df_test1[x][0])\n",
    "        \n",
    "        kpi_df_high = kpis_df[kpis_df['kpi']==x].iloc[0,1]\n",
    "        kpi_df_low = kpis_df[kpis_df['kpi']==x].iloc[0,2]\n",
    "        kpi_df_skew = kpis_df[kpis_df['kpi']==x].iloc[0,3]\n",
    "        kpi_df_kurt = kpis_df[kpis_df['kpi']==x].iloc[0,4]\n",
    "        \n",
    "        thd_high =  df_test[x][0] + (2 * df_test1[x][0])\n",
    "        thd_low =   df_test[x][0] - (2 * df_test1[x][0])\n",
    "        \n",
    "        \n",
    "        algo = rpt.Pelt(model=\"rbf\").fit(df_cell.iloc[i,:].values)\n",
    "        result = algo.predict(pen=penalty)\n",
    "        \n",
    "        \n",
    "        if len(result)>1:\n",
    "            cell_name = str(df_cell.iloc[i,:].head(0)).split(',')[1]\n",
    "            kpi_name = x\n",
    "            #TODO make sure u check for length of result before doing being line\n",
    "            value_avg = np.nanmean(df_cell.iloc[i,:][result[-2]:result[-1]]) #changing result[0] to result[-2] JB\n",
    "            \n",
    "            \n",
    "            if ((kpi_df_high > kpi_df_low and kpi_df_skew>=0) or (kpi_df_high==0 and kpi_df_low==0 and kpi_df_skew>=0)):\n",
    "                if value_avg > thd_high:\n",
    "                    stat = 'failed'\n",
    "                else:\n",
    "                    stat = 'passed'\n",
    "                    \n",
    "            \n",
    "            elif (kpi_df_high > kpi_df_low and kpi_df_skew<0 and kpi_df_kurt<=0):\n",
    "                if value_avg > thd_high:\n",
    "                    stat = 'failed'\n",
    "                else:\n",
    "                    stat = 'passed'\n",
    "                \n",
    "            \n",
    "            else:\n",
    "                if value_avg < thd_low:\n",
    "                    stat = 'failed'\n",
    "                else:\n",
    "                    stat = 'passed'\n",
    "                    \n",
    "                    \n",
    "            cells_ssv.append(cell_name)\n",
    "            kpi.append(kpi_name)\n",
    "            value.append(value_avg)\n",
    "            network_avg.append(df_test[x][0])\n",
    "            status.append(stat)\n",
    "            \n",
    "            \n",
    "            \n",
    "        else:\n",
    "            cell_name = str(df_cell.iloc[i,:].head(0)).split(',')[1]\n",
    "            kpi_name = x\n",
    "            value_avg = np.nanmean(df_cell.iloc[i,:][df_cell.iloc[i,:]<=high][df_cell.iloc[i,:]>=low])\n",
    "           \n",
    "            \n",
    "            if ((kpi_df_high > kpi_df_low and kpi_df_skew>=0) or (kpi_df_high==0 and kpi_df_low==0 and kpi_df_skew>=0)):\n",
    "                if (value_avg > thd_high):\n",
    "                    stat = 'failed'\n",
    "                else:\n",
    "                    stat = 'passed'\n",
    "                    \n",
    "            else:\n",
    "                if (value_avg < thd_low):\n",
    "                    stat = 'failed'\n",
    "                else:\n",
    "                    stat = 'passed'\n",
    "                    \n",
    "            cells_ssv.append(cell_name)\n",
    "            kpi.append(kpi_name)\n",
    "            value.append(value_avg)\n",
    "            network_avg.append(df_test[x][0])\n",
    "            status.append(stat)\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "ssv_table = pd.DataFrame([cells_ssv,kpi,value,network_avg,status], index=['cells', 'kpi','value','net_avg','status']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssv_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssv_table.to_csv(Tech+'_ssv_result.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
