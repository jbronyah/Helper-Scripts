{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncommment below line to install ruptures if not already installed\n",
    "\n",
    "# !python -m pip install ruptures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ruptures as rpt\n",
    "from scipy.stats import zscore, linregress, iqr, skew, kurtosis\n",
    "import numpy as np\n",
    "import xlsxwriter\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Please enter the below details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penalty = 3 # higher means less cells\n",
    "dim = 'Cell Name' # dimension you are interested in\n",
    "date = 'Date'     # date variable\n",
    "img_dir = \"C:/Users/BronyahJ/images/\" # path to store images\n",
    "source_file_path = \"C:\\\\Users\\\\BronyahJ\\\\Downloads\\\\\" # where your source data is located\n",
    "file_name = \"Worst_Cells_5G_Query_Result_20230212113700767.xlsx\" # source filename\n",
    "Tech = '5G'\n",
    "output_filename = 'worst_cells.xlsx'\n",
    "scale_data = True\n",
    "chg_thd = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify columns you want to delete in the to_delete list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REMOVE_NA = True\n",
    "to_delete = ['LocalCell Id','Integrity', 'Cell ID', 'Cell CI', 'CellIndex','NR Cell ID']\n",
    "KNOWN_NA_VALS = ['NIL', 'NILL', 'NULL', 'NA', '#NA', '#N/A', 'N/A','#VALUE!','#REF!','#DIV/0!','#NUM!','#NAME?','#NULL!','NAN','nan','NaN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_st = datetime.now()\n",
    "\n",
    "if str(file_name).split(\".\")[-1] == 'xlsx' or str(file_name).split(\".\")[-1] == 'xls':\n",
    "    df = pd.read_excel(source_file_path+file_name)\n",
    "    \n",
    "elif str(file_name).split(\".\")[-1] == 'csv':\n",
    "    df  = pd.read_csv(source_file_path+file_name,skiprows=6)\n",
    "\n",
    "imp_end= datetime.now()\n",
    "print(\"It took {} time to import data\".format(imp_end-imp_st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(to_delete) > 0:\n",
    "    df = df.drop([x for x in to_delete if x in df.columns], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################\n",
    "# Experimental code here. Trying to replace Known values which means NULL / NA to np.nan\n",
    "# Ideally this should help our analysis.\n",
    "############################################################################################\n",
    "for x in [x for x in df.columns if df[x].dtype.kind.lower() in ('o', 's', 'u', 'v')]:\n",
    "    if len(df[df[x].isin(KNOWN_NA_VALS)]) > 0: #some instances were found with Known NA substitutions\n",
    "        df.loc[ df[x].isin(KNOWN_NA_VALS), x ] = np.nan\n",
    "        print(\"Found some known NA substitutions in {}. Will replace and try to force as numeric\".format(x))\n",
    "    try: #now we will try to see if the column can become numeric\n",
    "        df[x] = pd.to_numeric(df[x], errors='raise')\n",
    "    except ValueError as e:\n",
    "        continue #Column cannot be converted to numeric. Just continue\n",
    "############################################################################################\n",
    "\n",
    "############################################################################################\n",
    "# Experiment 2: If all endings are % or $ or # then we will try to strip these and check if \n",
    "#     the column can be converted as a numeric value\n",
    "############################################################################################\n",
    "sp_endings = ['%', '$', '#', 'Â£', 'QAR', 'GBP', 'qar', 'gbp', 'usd', 'USD' ,'eur', 'EUR']\n",
    "\n",
    "for x in [x for x in df.columns if df[x].dtype.kind.lower() in ('o', 's', 'u', 'v')]:\n",
    "    for sp in sp_endings:\n",
    "        totals = df[x].astype(str).str.endswith(sp).sum() + df[x].isna().sum()\n",
    "        if totals == len(df): #Either all entries end with special char or are null\n",
    "            temp = df[x].astype(str).str.replace(sp, '')\n",
    "            try:\n",
    "                temp_numeric = pd.to_numeric(temp, errors='raise')\n",
    "                df[x] = temp_numeric #if we were able to convert to numeric then we keep this\n",
    "                                    # in our dataframe. else no change\n",
    "                print(\"Modified column {} for special endings {} and changed to numeric\".format(\n",
    "                        x, sp))\n",
    "            except ValueError as ve:\n",
    "                continue\n",
    "############################################################################################\n",
    "# Same code as above but for string beginnings\n",
    "\n",
    "for x in [x for x in df.columns if df[x].dtype.kind.lower() in ('o', 's', 'u', 'v')]:\n",
    "    for sp in sp_endings:\n",
    "        totals = df[x].astype(str).str.startswith(sp).sum() + df[x].isna().sum()\n",
    "        if totals == len(df): #Either all entries end with special char or are null\n",
    "            temp = df[x].astype(str).str.replace(sp, '')\n",
    "            try:\n",
    "                temp_numeric = pd.to_numeric(temp, errors='raise')\n",
    "                df[x] = temp_numeric #if we were able to convert to numeric then we keep this\n",
    "                                    # in our dataframe. else no change\n",
    "                print(\"Modified column {} for special startings {} and changed to numeric\".format(\n",
    "                        x, sp))\n",
    "            except ValueError as ve:\n",
    "                continue\n",
    "############################################################################################\n",
    "# Now we have to deal with NA values\n",
    "if REMOVE_NA == True:\n",
    "    df = df.dropna(axis=0, how='all')\n",
    "else:\n",
    "    for x in [x for x in df.columns]:\n",
    "        if df[x].dtype.kind in ('f', 'c', 'i', 'u'):\n",
    "            df[x].fillna(df[x].median(),inplace=True)\n",
    "    df = df.fillna(method='ffill')\n",
    "    df = df.fillna(method='bfill')\n",
    "############################################################################################\n",
    "\n",
    "    \n",
    "############################################################################################    \n",
    "# WARNING - DONT REMOVE BELOW WITHOUT UNDERSTANDING OF THE CODE BIT\n",
    "# This step is mandatory. We will delete any column if it is Completely np.nan\n",
    "a = df.isna().sum(axis=0)\n",
    "FULL_NA_COLS = [x for x in a[df.isna().sum(axis=0) == len(df)].index]\n",
    "df = df.drop(FULL_NA_COLS, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df01=df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df01 = df01.dropna(axis=0, how='any')\n",
    "df01.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worst Cell Detection and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_st = datetime.now()\n",
    "\n",
    "workbook = xlsxwriter.Workbook(Tech+str(datetime.now()).split(\" \")[0]+output_filename)\n",
    "\n",
    "\n",
    "for x in [x for x in df.columns if df[x].dtype.kind.lower() not in ('o', 's', 'u', 'v','m')]:\n",
    "    \n",
    "    df1= df.pivot_table(index=dim, columns=date, values=x, aggfunc=np.mean)\n",
    "    \n",
    "    cells = []\n",
    "    cells_2 = []\n",
    "    #cells_3 = []\n",
    "    net_avg = np.nanmean(df[x].values)\n",
    "    df2 = df1.index.to_list()\n",
    "    \n",
    "    \n",
    "    IQR = iqr(df[x].values, nan_policy='omit')\n",
    "    Q1 = np.nanpercentile(df[x].values,25)\n",
    "    Q3 = np.nanpercentile(df[x].values,75)\n",
    "    low_limit = Q1 - 1.5*IQR\n",
    "    high_limit = Q3 + 1.5*IQR\n",
    "    cutoff_low = np.nanmean(df[x].values) - (3*np.nanstd(df[x].values))\n",
    "    cutoff_high = np.nanmean(df[x].values) + (3*np.nanstd(df[x].values))\n",
    "    \n",
    "    sk = skew(df[x].values, nan_policy='omit')\n",
    "    kurt = kurtosis(df[x].values, nan_policy='omit')\n",
    "    \n",
    "    high_count = 0\n",
    "    low_count = 0\n",
    "    for i in np.arange(0,df01[x].shape[0]):\n",
    "        if (df01[x][i] >= high_limit) and (low_limit != high_limit):\n",
    "            high_count = high_count + 1\n",
    "            \n",
    "        elif (df01[x][i] <= low_limit) and (low_limit != high_limit) :\n",
    "            low_count = low_count + 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in np.arange(0,df1.shape[0]):\n",
    "        df3 = df1.iloc[i,:]\n",
    "        algo = rpt.Pelt(model=\"rbf\").fit(df3.values)\n",
    "        result = algo.predict(pen=penalty)\n",
    "        if len(result)>1:\n",
    "            cells.append(df2[i])\n",
    "        elif len(result)==1:\n",
    "            if ((sk>=0 and high_count>low_count and np.nanmean(df3.values)>cutoff_high) or (high_count==0 and low_count==0 and sk>=0 and np.nanmean(df3.values)>cutoff_high)):\n",
    "                cells_2.append(df2[i])\n",
    "            elif (high_count>low_count and sk<0 and kurt<=0 and np.nanmean(df3.values)>cutoff_high):\n",
    "                cells_2.append(df2[i])\n",
    "            elif ((sk<0 and high_count<low_count and np.nanmean(df3.values)<cutoff_low) or (high_count==0 and low_count==0 and sk<0 and np.nanmean(df3.values)<cutoff_low)):\n",
    "                cells_2.append(df2[i])\n",
    "            elif (high_count<low_count and sk<0 and kurt<=0 and np.nanmean(df3.values)<cutoff_low):\n",
    "                cells_2.append(df2[i])\n",
    "                \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    df4= df.pivot_table(index=dim, columns=date, values=x, aggfunc=np.mean)\n",
    "    \n",
    "    \n",
    "    if scale_data:\n",
    "        for i in np.arange(0,len(df4)):\n",
    "            df4.iloc[i] -= df4.iloc[i].min()\n",
    "            if (df4.iloc[i].max()-df4.iloc[i].min()) > 0:\n",
    "                df4.iloc[i] /= (df4.iloc[i].max()-df4.iloc[i].min())\n",
    "            else:\n",
    "                df4.iloc[i] = 0\n",
    "                \n",
    "            \n",
    "            \n",
    "        \n",
    "    \n",
    "    for i in np.arange(0,len(cells)):\n",
    "        df5 = df4.loc[cells[i]]\n",
    "        df6 = df1.loc[cells[i]]\n",
    "        algo = rpt.Pelt(model=\"rbf\").fit(df6.values)\n",
    "        result = algo.predict(pen=penalty)\n",
    "        chg_perc= (np.nanmean(df5[result[0]:result[-1]])- np.nanmean(df5[0:result[0]]))/(np.nanmean(df5[0:result[0]]) + 0.0000000000001)\n",
    "        slope = linregress(range(len(df5.values)), df5.values).slope\n",
    "        last_segment_avg = np.nanmean(df6[result[0]:result[-1]].values)\n",
    "        if ((sk>=0 and high_count>low_count) or (high_count==0 and low_count==0 and sk>=0)):\n",
    "            if abs(chg_perc)>chg_thd and slope>0 and last_segment_avg>=high_limit:\n",
    "                cells_2.append(cells[i])\n",
    "                \n",
    "        elif (high_count>low_count and sk<0 and kurt<=0):\n",
    "            if abs(chg_perc)>chg_thd and slope>0 and last_segment_avg>=high_limit:\n",
    "                cells_2.append(cells[i])\n",
    "                \n",
    "        else:\n",
    "            if abs(chg_perc)>chg_thd and slope<0 and last_segment_avg<=low_limit:\n",
    "                cells_2.append(cells[i])\n",
    "   \n",
    "\n",
    "  \n",
    "    \n",
    "    \n",
    "    worksheet = workbook.add_worksheet(name=str(x)[0:30])\n",
    "    worksheet.set_column('A:A', 30)\n",
    "    xl_col = 2\n",
    "    \n",
    "    if len(cells_2)>0:\n",
    "        for i in np.arange(0,len(cells_2)):\n",
    "            plt.figure(figsize = (10, 5))\n",
    "            algo = rpt.Pelt(model=\"rbf\").fit(df1.loc[cells_2[i]].values)\n",
    "            result = algo.predict(pen=penalty)\n",
    "            a=rpt.display(df1.loc[cells_2[i]].values, result)\n",
    "            plt.title(str(df1.loc[cells_2[i]].head(0)).split(',')[1])\n",
    "            plt.xticks(np.arange(0,len(df1.loc[cells_2[i]].values)),df1.loc[cells_2[i]].index,rotation='vertical')\n",
    "            img_path = os.path.join(img_dir,\"{}_{}_{}.png\".format(str(x)[0:5],str(datetime.now()).replace(\":\", \"_\"),i))\n",
    "            plt.savefig(img_path,bbox_inches=\"tight\")\n",
    "            plt.close()\n",
    "            worksheet.write('A'+str(xl_col), str(df1.loc[cells_2[i]].head(0)).split(',')[1])\n",
    "            worksheet.insert_image('B'+str(xl_col), img_path)\n",
    "            plt.close()\n",
    "            xl_col = xl_col + 20\n",
    "        \n",
    "    \n",
    "    \n",
    "workbook.close()\n",
    "        \n",
    "proc_end = datetime.now()\n",
    "\n",
    "print(\"It took {} time to process data\".format(proc_end-proc_st))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
